#summary How to use jmxtrans
#labels Featured

<wiki:toc max_depth="2" />

<wiki:gadget url="http://jmxtrans.googlecode.com/svn/wiki/adsense.xml" border="0" width="480" height="60" />

= Introduction =

jmxtrans is a tool which allows you to connect to any number of JVM's and query them for their attributes without writing a single line of Java code. The query language is based on JSON. The output is defined via OutputWriters. The context for the output is populated with a list of Result objects.

== Enabling JMX for a JVM ==

In order to use jmxtrans, you must first enable Java Management Extensions (JMX) on your Java Virtual Machine (JVM). I'm not going to cover that here in depth, however I will point you at some documentation.

  * [http://download.oracle.com/javase/1.5.0/docs/guide/management/agent.html JMX Agent Configuration]
  * [http://download.oracle.com/javase/1.5.0/docs/guide/management/ Monitoring and Management]

For applications behind a firewall that do not need security, add these arguments to the startup of the JVM in order to enable remote JMX connections:
{{{
-Dcom.sun.management.jmxremote.port=1105 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false
}}}

You should set the port number to any free port number on your machine that is above 1024.

== Engine Mode ==
There are two primary modes for using jmxtrans. The first is to use the JmxTransformer engine included with the distribution. This engine will read a directory of .json files, process them and then create 'jobs' to execute on a [http://www.quartz-scheduler.org/docs/tutorials/crontrigger.html cron-like schedule]. Each job maps to a server that you would like to query jmx attributes on. Therefore, you can setup a complex query schedule for each server by setting the cronExpression field on the Server object (by default it is every minute).

For a given json file, there can be an unlimited number of servers defined within it. The servers define the hostname, port, username and password. Within each server, there can be an unlimited number of queries executed against it.

Each Query executed against a server can output its results using any number of OutputWriters. jmxtrans includes several different OutputWriters that you can use.

The Queries expect an object ("java.lang.type=Memory"), zero or more attributes ["HeapMemoryUsage", "NonHeapMemoryUsage"] and one or more OutputWriters to send the Results of the query to. If you don't specify any attributes, then it will get all of them. You can also specify a star within an object name to query dynamically generated object names.

The JmxTransformer engine is fully multithreaded. You specify the maximum number of threads that you want to start up for each part of the application. By default, up to 10 servers are queried at the same time. It is also possible to have multiple threads for each query against a server. Thus, you can specify that you want 10 threads to
handle your 50 servers. Each one of your servers may have defined 10 queries. You can therefore, set the numQueryThreads to 2 to execute two queries against a server at the same time.

== API Mode ==
The second mode for jmxtrans is to act as an API to build your own application for pulling data from JMX and writing it out. The Engine was written on top of this API. It is how I'd use this project, but maybe you have other ideas so that is fully supported as well by allowing you to write your own engine.

jmxtrans uses the amazing [http://jackson.codehaus.org/ Jackson library] to parse json data into a Java object model. This model is primarily represented by the [http://code.google.com/p/jmxtrans/source/browse/#svn%2Ftrunk%2Fsrc%2Fcom%2Fgooglecode%2Fjmxtrans%2Fmodel JmxProcess, Server, Query, Result] objects. This means that if you know a bit of java, it is possible to fully customize your own usage of jmxtrans to however you see fit.

The core of the api is implemented as mostly static methods in the [http://code.google.com/p/jmxtrans/source/browse/trunk/src/com/googlecode/jmxtrans/util/JmxUtils.java JmxUtils class]. You effectively Pass in a Server object with a bunch of Queries and get back a list of Results. How you process those results is up to you.

It also means that you can use Java'ish languages like Jython, Scala and Groovy to script jmxtrans to do whatever you want.

Take a look at the included [http://code.google.com/p/jmxtrans/source/browse/#svn/trunk/src/com/googlecode/jmxtrans/example example classes]. They show how you can either read a json file from disk into the object model or create the object model by hand and execute it. There is also examples of using wildcards, which jmxtrans fully supports with JDK 6.

= Configuration Details =

This is an example configuration file which hits one server and makes 3 different queries against it for data. The queries will be started up in threads so that at most, two queries are executing at the same time.

{{{
{
  "servers" : [ {
    "port" : "1099",
    "host" : "w2",
    "numQueryThreads" : 2,
    "queries" : [ {
      "obj" : "java.lang:type=Memory",
      "attr" : [ "HeapMemoryUsage", "NonHeapMemoryUsage" ],
      "outputWriters" : [ {
        "@class" : "com.googlecode.jmxtrans.model.output.StdOutWriter",
        "settings" : {
        }
      } ]
    }, {
      "obj" : "java.lang:name=CMS Old Gen,type=MemoryPool",
      "attr" : [ "Usage" ],
      "outputWriters" : [ {
        "@class" : "com.googlecode.jmxtrans.model.output.StdOutWriter",
        "settings" : {
        }
      } ]
    }, {
      "obj" : "java.lang:name=ConcurrentMarkSweep,type=GarbageCollector",
      "attr" : [ "LastGcInfo" ],
      "outputWriters" : [ {
        "@class" : "com.googlecode.jmxtrans.model.output.StdOutWriter",
        "settings" : {
        }
      } ]
    } ]
  } ]
}
}}}

= Jmx Transformer =

There is a main() class in the jar file that is useful for watching a directory and executing any .json files in that directory. The command line arguments are:

{{{
usage: java -jar jmxtrans-all.jar
 -e         Run endlessly. Default false.
 -h         Help
 -j <arg>   Directory where json configuration is stored. Default is .
 -f <arg>   A single json file to execute.
 -q <arg>   Path to quartz configuration file.
 -s <arg>   Seconds between server job runs (not defined with cron).
            Default: 60
}}}

If you pass the -e argument, the JVM will stay running forever. You may want to background the process and redirect stdout to a file so you can check the execution progress.

The engine will run through the list of .json files that it finds in the -j directory. 

The -f option is like the -j option, but you pass in the path to a single .json file.

If you add, remove or modify a file while the process is running with -e, that change will be picked up and jobs will either be started, removed or restarted. That way, you should be able to keep the process running indefinitely and only have to restart to run a new version of jmxtrans.

= Writing Results =

OutputWriter's are very powerful. They allow you to easily transform your Queries into whatever format you want. For example, the author is using the included RRDToolWriter to write out rrd database files so that Cacti can read them in directly and create graphs. This allows sysadmins who may not be Java experts to quickly and easily add graphing of any Java system without writing code.

*The recommended way to use jmxtrans is to use the Graphite Writer over the RRDToolWriter*. The reason is that Graphite lends itself more easily to a schemaless database. The issue is that JMX produces a fairly complicated set of data and defining how that data should be stored can be difficult. Graphite/jmxtrans gets around this by taking advantage of the fact that Graphite expects its data columns in a dot notation and doesn't require defining any sort of schema in advance. On the other hand RRD requires a schema to be defined and that can be a pain to setup (even though JMX trans will generate most of the configuration information for you by turning on debugging). That said, once you have the RRD schema, you still need to configure Cacti to read that schema and that is also a pain. Since this tool aims to keep things simple, your best shot at getting pretty graphs setup in a short amount of time is to use the Graphite Writer.

== Standard Out Writer ==

This is a basic writer that just prints the list of Results from a Query to System.out. This makes debugging your Queries a lot easier.

== Graphite Writer ==

[http://graphite.wikidot.com/ Graphite] is a very cool graphing mechanism that is similar to Cacti, but far easier to setup since you don't have to become a RRD expert. All you have to do to configure jmxtrans to use Graphite is to setup the GraphiteWriter with a host and port and the writer will send what ever you want to graph to it.

Here is an example .json file that outputs HeapMemoryUsage and NonHeapMemoryUsage directly to graphite:

{{{
{
  "servers" : [ {
    "port" : "1099",
    "host" : "w2",
    "queries" : [ {
      "obj" : "java.lang:type=Memory",
      "attr" : [ "HeapMemoryUsage", "NonHeapMemoryUsage" ],
      "outputWriters" : [ {
        "@class" : "com.googlecode.jmxtrans.model.output.GraphiteWriter",
        "settings" : {
          "port" : 2003,
          "host" : "192.168.192.133"
        }
      } ]
    } ]
  } ]
}
}}}

This produces the following screen shot. It was not necessary to tell graphite anything about the 'tree' that was created as it was generated automatically by GraphiteWriter. [http://code.google.com/p/jmxtrans/source/browse/trunk/src/com/googlecode/jmxtrans/example/Graphite.java This is the example Java code to generate] the above json.

http://jmxtrans.googlecode.com/svn/wiki/render.png

== RRDTool Writer ==

This is a slightly more complicated writer that relies heavily on convention based configuration. You *must* have rrdtool installed on the machine you are planning on running this on. Let's start off with an example configuration for for the OutputWriter:

{{{
{
  "servers" : [ {
    "port" : "1099",
    "host" : "w2",
    "queries" : [ {
      "obj" : "java.lang:type=Memory",
      "attr" : [ "HeapMemoryUsage", "NonHeapMemoryUsage" ],
      "outputWriters" : [ {
        "@class" : "com.googlecode.jmxtrans.model.output.RRDToolWriter",
        "settings" : {
            "templateFile" : "heapmemory-rrd-template.xml",
            "outputFile" : "target/heap.rrd",
            "binaryPath" : "/opt/local/bin",
            "debug" : true,
            "generate" : true
        }
      } ]
    } ]
  } ]
}
}}}

There are three configuration options that are all required in order for RRDToolWriter to work.

  * *templateFile* is the path to the [http://code.google.com/p/jmxtrans/source/browse/trunk/heapmemory-rrd-template.xml heapmemory-rrd-template.xml] file which configures the database schema. This file is primarily documented on the [http://oldwww.jrobin.org/api/templatesapi.html JRobin website] and it mirrors the configuration options for [http://oss.oetiker.ch/rrdtool/doc/rrdcreate.en.html 'rrdtool create'], so I won't go into too much detail here.
  * *outputFile* is the path to the rrd database file that will get automatically created if it doesn't already exist.
  * *binaryPath* is the path to the directory that contains the rrdtool binary for your platform. That binary is used to create the database and write data to it. This isn't the most efficient way of doing things, but unfortunately is the easiest option using Java.
  * *debug* is an optional setting that defaults to false. When it is on, it will print out the generated datasource name that you would use in the template.xml file to record the numbers that you want to keep track of. These names are shortened versions of the attribute name initials.
  * *generate* will output, to the log, example datasource xml that you can copy/paste into the template.xml file. This is what is used to create your rrd database. If you have a lot of datasources, this will save you some typing. Note, this only works if you have debug enabled as well.

RRDToolWriter will first read in the template.xml file and create a database based on that file. The datasources (aka: 'columns') must match up to the values in the the Results. For example, if you have a Query that returns a Result that has the values 'commmitted' and 'max', then you will need to have two datasources named 'committed' and 'max'. This is the part where convention based configuration is employed. Enable debug mode to see what the names of the generated columns are. They are shortened because datasources have a maximum length of 20 characters. You may need to throw away your first couple of rrd files in order to get the schema (datasource name mapping) correct.

Only the datasources which are defined in the template.xml file are used to lookup the values as part of the Results. Thus, you can have a Query which returns Results that has many values. You only need to define datasources for the values that you want to store. Once you have created the rrd file, there is no way to modify the schema unless you use the rrdtool from the command line.